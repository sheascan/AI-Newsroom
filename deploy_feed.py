import os
import shutil
import json
import glob
from datetime import datetime, timezone
from feedgen.feed import FeedGenerator
from dateutil import parser

# --- CONFIGURATION ---
# 1. Local path where 'main_gen139.py' saves data
LOCAL_OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "outputs")

# 2. Your Local Dropbox Folder (Where files should be copied TO)
DROPBOX_LOCAL_DIR = os.path.expanduser("~/Dropbox/Public/Podcast_Output")

# 3. The Public URL Prefix (How the internet finds those files)
#    IMPORTANT: Ensure this ends with a slash '/'
#    Example: "https://dl.dropboxusercontent.com/u/123456/Podcast_Output/"
PUBLIC_URL_BASE = "https://dl.dropboxusercontent.com/home/Public/Podcast_Output" 

# 4. Feed Metadata
FEED_CONFIG = {
    "title": "My AI Daily Briefing",
    "link": PUBLIC_URL_BASE,
    "description": "Daily automated news summaries generated by AI.",
    "author": "AI Studio",
    "language": "en"
}

def sync_folders():
    """Copies new folders from Local Output to Dropbox."""
    if not os.path.exists(DROPBOX_LOCAL_DIR):
        os.makedirs(DROPBOX_LOCAL_DIR)

    print(f"üîÑ Syncing from {LOCAL_OUTPUT_DIR} -> {DROPBOX_LOCAL_DIR}")
    
    # Iterate through Day folders (e.g., "20Dec")
    for day_folder in os.listdir(LOCAL_OUTPUT_DIR):
        src_path = os.path.join(LOCAL_OUTPUT_DIR, day_folder)
        dst_path = os.path.join(DROPBOX_LOCAL_DIR, day_folder)
        
        if os.path.isdir(src_path):
            # If destination doesn't exist, copy the whole tree
            if not os.path.exists(dst_path):
                shutil.copytree(src_path, dst_path)
                print(f"   ‚úÖ Copied new day: {day_folder}")
            else:
                # Simple check: Copy missing files only
                for filename in os.listdir(src_path):
                    s_file = os.path.join(src_path, filename)
                    d_file = os.path.join(dst_path, filename)
                    if not os.path.exists(d_file):
                        shutil.copy2(s_file, d_file)
                        print(f"   -> Updated file: {filename}")

def generate_rss():
    """Scans Dropbox folder for manifest.json files and builds podcast.xml"""
    print("\nüéôÔ∏è  Generating RSS Feed...")
    
    fg = FeedGenerator()
    fg.load_extension('podcast')
    
    # Set Feed Metadata
    fg.title(FEED_CONFIG["title"])
    fg.link(href=FEED_CONFIG["link"], rel='alternate')
    fg.description(FEED_CONFIG["description"])
    fg.language(FEED_CONFIG["language"])
    
    # Find all manifest.json files in the Dropbox folder (recursively or flat)
    # Looking for structure: Dropbox/20Dec/manifest.json
    manifest_pattern = os.path.join(DROPBOX_LOCAL_DIR, "*", "manifest.json")
    manifests = glob.glob(manifest_pattern)
    manifests.sort(key=os.path.getmtime, reverse=True) # Newest folders first

    print(f"   found {len(manifests)} manifests.")

    for m_file in manifests:
        try:
            with open(m_file, 'r') as f:
                data = json.load(f)
                
            folder_name = os.path.basename(os.path.dirname(m_file)) # e.g., "20Dec"
            
            # Parse folder date for default pubDate (assuming "20Dec" format)
            # We add current year if missing, handling year boundaries is tricky without full date
            # Ideally, use file creation time or store full date in manifest.
            try:
                base_date = datetime.strptime(f"{folder_name} {datetime.now().year}", "%d%b %Y")
                base_date = base_date.replace(tzinfo=timezone.utc)
            except:
                # Fallback to file modification time
                base_date = datetime.fromtimestamp(os.path.getmtime(m_file), tz=timezone.utc)

            for ep in data.get("episodes", []):
                fe = fg.add_entry()
                fe.title(ep['title'])
                fe.id(ep['filename']) # Unique ID
                
                # Construct Public URL
                # URL Structure: BASE / Folder / Filename
                # Ensure filename is URL encoded if it has spaces (simple replace for now)
                safe_filename = ep['filename'].replace(" ", "%20")
                public_url = f"{PUBLIC_URL_BASE}{folder_name}/{safe_filename}"
                
                fe.link(href=public_url)
                
                # Enclosure (The Audio File) is mandatory for Podcasts
                # We need file size for the enclosure
                local_audio_path = os.path.join(DROPBOX_LOCAL_DIR, folder_name, ep['filename'])
                file_size = 0
                if os.path.exists(local_audio_path):
                    file_size = os.path.getsize(local_audio_path)
                
                fe.enclosure(public_url, str(file_size), 'audio/mpeg')
                
                # PubDate (Use file mtime or folder date)
                fe.pubDate(base_date)
                
                # Build Description from Sources
                desc = "Sources:\n"
                for s in ep.get('sources', []):
                    desc += f"- {s['title']} ({s['url']})\n"
                fe.description(desc)

        except Exception as e:
            print(f"   ‚ö†Ô∏è Error reading {m_file}: {e}")

    # Output to file
    rss_path = os.path.join(DROPBOX_LOCAL_DIR, "podcast.xml")
    fg.rss_file(rss_path)
    print(f"   ‚ú® Feed published to: {rss_path}")

if __name__ == "__main__":
    sync_folders()
    generate_rss()